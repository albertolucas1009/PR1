{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images downloaded\n",
      "Scraping successful\n",
      "csv created\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import re\n",
    "import argparse\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from itertools import zip_longest\n",
    "#from selenium import webdriver\n",
    "from lxml import html, etree\n",
    "\n",
    "# Establecemos una clase que contenga las funciones del scraper para que pueda ser reutilizado\n",
    "class MoviesToday ():\n",
    "    \n",
    "\n",
    "    # Función que descarga la página en la que vamos a realizar el web scraping    \n",
    "    def _download_web (url):\n",
    "        \n",
    "        reply = urllib.request.Request(url, data = None, headers = {\n",
    "        'User-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36'\n",
    "        })\n",
    "        response = urllib.request.urlopen(url, timeout = 10)\n",
    "        html = response.read()\n",
    "        return html \n",
    "    \n",
    "    \n",
    "    # Función que realiza el scraping y devuelve la información que queremos obtener sobre las películas\n",
    "    def get_movies_info (url):\n",
    "        \n",
    "        # Utilizamos Beautiful Soup para realizar el scraping\n",
    "      \n",
    "        response = urllib.request.urlopen(url, timeout = 10)\n",
    "        html = response.read()\n",
    "        bs = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # Declaramos una lista para cada elemento de información que deseamos obtener sobre cada película\n",
    "        names = []\n",
    "        directors = []\n",
    "        casting = []\n",
    "        genres = []\n",
    "        ratings = []\n",
    "        links = []\n",
    "        \n",
    "        # Realizamos el scraping sobre la tabla que contiene las películas en cartelera y su información\n",
    "        table = bs.findAll('table', id='main-content-table')\n",
    "        table = table [0]\n",
    "\n",
    "\n",
    "        # Obtenemos la información de interés que está en una tabla. \n",
    "        # Recorremos la tabla extrayendo la información deseada y almacenándola en las listas creadas anteriormente\n",
    "        for row in table.find_all ('tr'):\n",
    "    \n",
    "            for cell in row.find_all ('td'):\n",
    "        \n",
    "                for title in cell.find_all ('div', {\"class\": \"mc-right\"}):\n",
    "                    \n",
    "                    # Extraemos el título \n",
    "                    data =title.h3\n",
    "                    data = data.get_text()\n",
    "                    names.append(data)\n",
    "            \n",
    "                    # Extraemos el director \n",
    "                    director = title.find ('div', {\"class\": \"director\"})\n",
    "                    director = director.get_text()\n",
    "                    director = director.replace('\\n', '')\n",
    "                    directors.append(director)\n",
    "            \n",
    "                    # Extraemos el reparto\n",
    "                    cast = title.find ('div', {\"class\" : \"cast\"})\n",
    "                    cast = cast.get_text()\n",
    "                    cast = cast.replace('\\n', '')\n",
    "                    casting.append(cast)\n",
    "            \n",
    "                    # Extraemos el género\n",
    "                    genre = title.find ('a', {\"class\" : \"genre\"})\n",
    "                    genre = genre.get_text()\n",
    "                    genres.append (genre)\n",
    "           \n",
    "                    # Extraemos la valoración\n",
    "                    rating = title.find ('div', {\"class\" : \"avg-rating\"})\n",
    "                    rating = rating.get_text()\n",
    "                    ratings.append (rating)\n",
    "             \n",
    "            # Recorremos de nuevo la tabla y ahora extraemos el enlace de cada película\n",
    "            for row in table.find_all ('tr'):\n",
    "    \n",
    "                for cell in row.find_all ('td'):\n",
    "        \n",
    "                    for title in cell.find_all ('div', {\"class\": \"mc-right\"}):\n",
    "            \n",
    "                        trailer = title.find ('a')\n",
    "                        link = trailer.get('href')\n",
    "                        links.append(link)\n",
    "\n",
    "        # Declaramos una lista que contiene las listas creadas anteriormente y modificamos su formato para exportarla a csv\n",
    "        info = [names, directors, casting, genres, ratings, links]\n",
    "        export_data = zip_longest(*info, fillvalue= '')\n",
    "        \n",
    "        print ('Scraping successful')\n",
    "        return export_data\n",
    "        \n",
    "        \n",
    "    # Función que descarga una imagen del póster de cada película\n",
    "    def _download_images (html):\n",
    "        \n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup (page.content)\n",
    "\n",
    "        images = []\n",
    "\n",
    "        # Creamos una lista que contenga las imágenes que vamos a descargar\n",
    "        for row in soup.find_all ('tr'):\n",
    "    \n",
    "            for cell in row.find_all ('td'):\n",
    "\n",
    "                for img in cell.find_all('div', {\"class\": \"mc-left\"}):\n",
    "            \n",
    "                    image = img.find('img')\n",
    "                    image = image.get('src')\n",
    "                    images.append(image)        \n",
    "\n",
    "        # Descargamos las imágenes de la lista     \n",
    "        for image in images:\n",
    "    \n",
    "            filename = image.split(\"/\")[-1]\n",
    "    \n",
    "            rawImage = requests.get(image, stream = True)\n",
    "    \n",
    "            with open (filename, 'wb') as fd:\n",
    "        \n",
    "                for chunk in rawImage.iter_content(chunk_size = 1024):\n",
    "                    fd.write(chunk)\n",
    "    \n",
    "        print ('Images downloaded')\n",
    "\n",
    "    \n",
    "    # Función que exporta la información de nuestro scraper a un archivo csv\n",
    "    def data2csv (export_data):\n",
    "        \n",
    "        with open ('cinema.csv', 'w', newline = '') as r:\n",
    "            wr = csv.writer(r)\n",
    "            wr.writerow(('Names', 'Directors', 'Cast', 'Genre', 'Rating', 'Link'))\n",
    "            wr.writerows(export_data)\n",
    "        r.close()\n",
    "        \n",
    "        print ('csv created')\n",
    "        #return 'csv created'\n",
    "\n",
    "url = 'https://www.filmaffinity.com/uk/topcat.php?id=new_th_uk'       \n",
    "    \n",
    "# Para ejecutar el scraper, ejecutamos las funciones creadas anteriormente   \n",
    "MoviesToday();\n",
    "MoviesToday._download_images (html);\n",
    "MoviesToday._download_web(url);\n",
    "MoviesToday.data2csv (MoviesToday.get_movies_info (url));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
